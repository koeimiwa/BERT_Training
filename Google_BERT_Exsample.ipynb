{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google_BERT_Exsample.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2zUBxav2XuBXMY0gLlbcA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv5aJYt42erW"
      },
      "source": [
        "# Transformerをセットアップ\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6NlS4C_26hS"
      },
      "source": [
        "# その他ライブラリインストール\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "!pip install fugashi ipadic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d4J91w72-TH"
      },
      "source": [
        "# 必要なライブラリをインポート\n",
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
        "\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "text = '父の父は、祖父。'\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "print(tokenized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpg-fUhe3PmF"
      },
      "source": [
        "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
        "masked_index = 2\n",
        "tokenized_text[masked_index] = '[MASK]'\n",
        "print(tokenized_text)\n",
        "\n",
        "# Convert token to vocabulary indices\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "print(indexed_tokens)\n",
        "\n",
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "print(tokens_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChD1s4dT3Xm1"
      },
      "source": [
        "# Load pre-trained model\n",
        "model_mask = BertForMaskedLM.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "model_mask.eval()\n",
        "\n",
        "# Predict\n",
        "with torch.no_grad():\n",
        "    outputs = model_mask(tokens_tensor)\n",
        "    predictions = outputs[0][0, masked_index].topk(5) # 予測結果の上位5件を抽出\n",
        "\n",
        "# Show results\n",
        "for i, index_t in enumerate(predictions.indices):\n",
        "    index = index_t.item()\n",
        "    token = tokenizer.convert_ids_to_tokens([index])[0]\n",
        "    print(i, token)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}